{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = []\n",
    "    ExpReg = nltk.RegexpTokenizer(r'(\\b[A-Za-z.]+\\b|\\d+(?:\\.\\d+)?)')\n",
    "    tokens = ExpReg.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words(tokens):\n",
    "    nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokens_without_stopwords = []\n",
    "    tokens_without_stopwords = [word for word in tokens if word.lower() not in nltk_stopwords]\n",
    "    return tokens_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(tokens): #stemming\n",
    "    Porter = nltk.PorterStemmer()\n",
    "    normalized_words = []\n",
    "    normalized_words = [Porter.stem(word) for word in tokens]\n",
    "    return normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre de tokens dans le fichier  text1.txt  =  78\n",
      "Ses mots et leurs frequences : [('univers', 3), ('estim', 1), ('13.8', 1), ('billion', 1), ('year', 1), ('old', 1), ('base', 1), ('observ', 1), ('cosmic', 1), ('microwav', 1), ('background', 1), ('radiat', 2), ('afterglow', 1), ('big', 1), ('bang', 1), ('provid', 1), ('us', 1), ('snapshot', 1), ('earli', 2), ('histori', 1), ('einstein', 2), ('theori', 2), ('rel', 1), ('formul', 1), ('20', 1), ('centuri', 1), ('revolution', 1), ('understand', 1), ('space', 2), ('time', 2), ('predict', 1), ('phenomena', 1), ('bend', 1), ('light', 1), ('graviti', 1), ('warp', 1), ('concept', 1), ('black', 1), ('hole', 1), ('larg', 1), ('hadron', 1), ('collid', 1), ('lhc', 1), ('one', 1), ('advanc', 1), ('scientif', 1), ('instrument', 1), ('ever', 1), ('built', 1), ('locat', 1), ('near', 1), ('geneva', 1), ('switzerland', 1), ('design', 1), ('explor', 1), ('fundament', 1), ('question', 1), ('march', 1), ('14', 1), ('1879', 1), ('signific', 1), ('date', 1), ('world', 1), ('scienc', 1), ('mark', 1), ('birth', 1), ('albert', 1), ('1.61803398875', 1), ('known', 1), ('golden', 1), ('ratio', 1), ('mathemat', 1), ('constant', 1), ('numer', 1), ('applic', 1), ('art', 1), ('architectur', 1), ('natur', 1)]\n",
      "*************************************************************\n",
      "le nombre de tokens dans le fichier  text2.txt  =  27\n",
      "Ses mots et leurs frequences : [('juli', 1), ('4', 1), ('1776', 1), ('date', 1), ('great', 1), ('histor', 1), ('signific', 1), ('unit', 1), ('state', 1), ('12345', 1), ('main', 1), ('street', 1), ('apart', 1), ('678', 1), ('quick', 1), ('brown', 1), ('fox', 1), ('jump', 1), ('12', 1), ('lazi', 1), ('dog', 1), ('today', 1), ('weather', 1), ('forecast', 1), ('75', 1), ('f', 1), ('sunni', 1)]\n",
      "*************************************************************\n",
      "le nombre de tokens dans le fichier  text3.txt  =  96\n",
      "Ses mots et leurs frequences : [('renew', 8), ('energi', 15), ('stand', 1), ('pivot', 1), ('solut', 1), ('address', 1), ('global', 5), ('climat', 1), ('crisi', 1), ('impress', 1), ('number', 1), ('support', 1), ('signific', 1), ('type', 1), ('solar', 2), ('industri', 1), ('boom', 1), ('cumul', 1), ('instal', 1), ('capac', 1), ('exceed', 1), ('760', 1), ('gw', 2), ('2021', 1), ('accord', 1), ('intern', 2), ('agenc', 1), ('iea', 2), ('wind', 3), ('power', 1), ('major', 1), ('player', 1), ('account', 1), ('approxim', 1), ('8', 1), ('world', 2), ('electr', 2), ('gener', 1), ('2020', 3), ('report', 2), ('council', 1), ('gwec', 1), ('hydropow', 3), ('remain', 2), ('domin', 1), ('forc', 1), ('provid', 2), ('16', 1), ('2018', 1), ('per', 1), ('associ', 1), ('iha', 1), ('geotherm', 2), ('sector', 2), ('smaller', 1), ('continu', 1), ('grow', 1), ('steadili', 1), ('potenti', 1), ('substanti', 1), ('baseload', 1), ('biomass', 2), ('versatil', 1), ('sourc', 2), ('estim', 1), ('suggest', 1), ('could', 1), ('contribut', 2), ('60', 1), ('advantag', 1), ('reduc', 1), ('carbon', 1), ('emiss', 2), ('2.6', 1), ('reduct', 1), ('2', 1), ('say', 1), ('job', 2), ('creation', 1), ('employ', 1), ('12', 1), ('million', 1), ('peopl', 1), ('worldwid', 1), ('2019', 1), ('annual', 1), ('review', 1), ('econom', 2), ('benefit', 1), ('u.', 1), ('invest', 1), ('55.5', 1), ('billion', 1), ('drive', 1), ('growth', 1), ('innov', 1)]\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(os.path.abspath(\"text files\")): \n",
    "    with open(os.path.join(\"text files\", filename), \"r\") as file:\n",
    "        text = file.read()\n",
    "        tokens = tokenization(text)\n",
    "        tokens_without_stopwords = stop_words(tokens)\n",
    "        normalized_words = normalization(tokens_without_stopwords)\n",
    "        words_frequency = nltk.FreqDist(normalized_words)\n",
    "        print(\"le nombre de tokens dans le fichier \", filename, \" = \", len(words_frequency))\n",
    "        print(\"Ses mots et leurs frequences :\", [(word, freq) for word, freq in words_frequency.items()])\n",
    "        print(\"*************************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
