{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import re\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = []\n",
    "    ExpReg = nltk.RegexpTokenizer('(?:[A-Za-z]\\.)+|[A-Za-z]+[\\-@]\\d+(?:\\.\\d+)?|\\d+[A-Za-z]+|\\d+(?:[\\.\\,]\\d+)?%?|\\w+(?:[\\-/]\\w+)*')\n",
    "    tokens = ExpReg.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words(tokens):\n",
    "    nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "    tokens_without_stopwords = []\n",
    "    tokens_without_stopwords = [word for word in tokens if word.lower() not in nltk_stopwords]\n",
    "    return tokens_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_porter(tokens): #stemming\n",
    "    Porter = nltk.PorterStemmer()\n",
    "    normalized_words = []\n",
    "    normalized_words = [Porter.stem(word) for word in tokens]\n",
    "    return normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_lancaster(tokens): #stemming\n",
    "    Lancaster = nltk.LancasterStemmer()\n",
    "    normalized_words = []\n",
    "    normalized_words = [Lancaster.stem(word) for word in tokens]\n",
    "    return normalized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def index(files, Inverse, Tokenize, PorterStemmer):\n",
    "    word_file_count = defaultdict(set)\n",
    "    d = {}\n",
    "    dict = {}\n",
    "    for filename in files: \n",
    "        with open(os.path.join(\"Collection\", filename), \"r\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "            if Tokenize:\n",
    "                tokens = tokenization(text)\n",
    "            else:\n",
    "                tokens = text.split()\n",
    "\n",
    "            tokens_without_stopwords = stop_words(tokens)\n",
    "\n",
    "            if PorterStemmer:\n",
    "                normalized_words = normalization_porter(tokens_without_stopwords)\n",
    "            else:\n",
    "                normalized_words = normalization_lancaster(tokens_without_stopwords)\n",
    "\n",
    "            words_frequency = nltk.FreqDist(normalized_words)\n",
    "\n",
    "            file_id = int(re.search(r'\\d+', os.path.basename(filename)).group())\n",
    "\n",
    "            for word in words_frequency.keys():\n",
    "                if Inverse:\n",
    "                    if word in d:\n",
    "                        d[word].append((file_id, words_frequency[word], max(list(words_frequency.values()))))\n",
    "                    else:\n",
    "                        d[word] = [(file_id, words_frequency[word], max(list(words_frequency.values())))]\n",
    "                else:\n",
    "                    if file_id in d:\n",
    "                        d[file_id].append((word, words_frequency[word], max(list(words_frequency.values()))))\n",
    "                    else:\n",
    "                        d[file_id] = [(word, words_frequency[word], max(list(words_frequency.values())))]\n",
    "\n",
    "                    word_file_count[word].add(file_id)  \n",
    "\n",
    "\n",
    "    for key1, values in d.items():\n",
    "        for (key2, freq, max_freq) in values:\n",
    "                if Inverse:\n",
    "                    value = (key2, freq, (freq / max_freq) * np.log10(((len(files) / len(d[key1]))+1)))\n",
    "                else: \n",
    "                    value = (key2, freq, (freq / max_freq) * np.log10(((len(files) / len(word_file_count[key2]))+1)))\n",
    "                if key1 in dict:\n",
    "                    dict[key1].append(value)\n",
    "                else:\n",
    "                    dict[key1] = [value]\n",
    "                    \n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_file(dictionary, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for key, values in dictionary.items():\n",
    "            for value in values:\n",
    "                (files_list, freq, weight) = value\n",
    "                file.write(f\"{key} {files_list} {freq} {weight:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_relevance_to_file(list, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for key, value in list:\n",
    "            file.write(f\"{key} {value:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'research': [(1, 2, 0.19084850188786498), (3, 3, 0.17892047051987342), (6, 2, 0.08674931903993863)], 'success': [(1, 1, 0.16901960800285137)], 'appli': [(1, 1, 0.16901960800285137)], 'larg': [(1, 1, 0.07958800173440753), (2, 1, 0.0497425010840047), (3, 1, 0.0497425010840047), (4, 1, 0.04421555651911529)], 'languag': [(1, 1, 0.09542425094393249), (3, 1, 0.059640156839957804), (4, 1, 0.05301347274662915)], 'model': [(1, 3, 0.1806179973983887), (2, 7, 0.26340124620598354), (3, 1, 0.03762874945799765), (4, 2, 0.06689555459199582), (5, 1, 0.06020599913279624), (6, 11, 0.3010299956639812)], 'llm': [(1, 3, 0.28627275283179743), (3, 2, 0.11928031367991561), (4, 2, 0.1060269454932583)], 'chatgpt': [(1, 1, 0.16901960800285137)], 'rerank': [(1, 5, 0.8450980400142568)], 'inform': [(1, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'retriev': [(1, 1, 0.06848453616444126), (2, 3, 0.12840850530832737), (3, 3, 0.12840850530832737), (5, 2, 0.13696907232888253), (6, 1, 0.031129334620200573)], 'context': [(1, 1, 0.16901960800285137)], 'date': [(1, 1, 0.16901960800285137)], 'work': [(1, 2, 0.24082399653118497), (5, 1, 0.12041199826559248)], 'mostli': [(1, 1, 0.16901960800285137)], 'built': [(1, 1, 0.16901960800285137)], 'proprietari': [(1, 1, 0.16901960800285137)], 'hidden': [(1, 1, 0.16901960800285137)], 'behind': [(1, 2, 0.33803921600570275)], 'opaqu': [(1, 1, 0.16901960800285137)], 'api': [(1, 1, 0.16901960800285137)], 'endpoint': [(1, 1, 0.16901960800285137)], 'approach': [(1, 1, 0.09542425094393249), (3, 1, 0.059640156839957804), (4, 9, 0.47712125471966244)], 'yield': [(1, 1, 0.12041199826559248), (2, 1, 0.0752574989159953)], 'experiment': [(1, 2, 0.24082399653118497), (4, 1, 0.06689555459199582)], 'result': [(1, 2, 0.13696907232888253), (2, 3, 0.12840850530832737), (3, 1, 0.042802835102775785), (4, 1, 0.0380469645358007), (6, 1, 0.031129334620200573)], 'reproduc': [(1, 1, 0.16901960800285137)], 'non-determinist': [(1, 1, 0.16901960800285137)], 'threaten': [(1, 1, 0.16901960800285137)], 'verac': [(1, 1, 0.16901960800285137)], 'outcom': [(1, 1, 0.16901960800285137)], 'build': [(1, 1, 0.16901960800285137)], 'shaki': [(1, 1, 0.16901960800285137)], 'foundat': [(1, 2, 0.33803921600570275)], 'address': [(1, 1, 0.07958800173440753), (2, 1, 0.0497425010840047), (3, 1, 0.0497425010840047), (6, 1, 0.03617636442473069)], 'signific': [(1, 1, 0.12041199826559248), (3, 1, 0.0752574989159953)], 'shortcom': [(1, 1, 0.16901960800285137)], 'present': [(1, 1, 0.16901960800285137)], 'rankvicuna': [(1, 1, 0.16901960800285137)], 'first': [(1, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'fulli': [(1, 1, 0.16901960800285137)], 'open-sourc': [(1, 1, 0.16901960800285137)], 'capabl': [(1, 1, 0.12041199826559248), (2, 1, 0.0752574989159953)], 'perform': [(1, 1, 0.06848453616444126), (2, 2, 0.08560567020555157), (3, 2, 0.08560567020555157), (5, 2, 0.13696907232888253), (6, 1, 0.031129334620200573)], 'high-qual': [(1, 1, 0.16901960800285137)], 'listwis': [(1, 1, 0.12041199826559248), (4, 1, 0.06689555459199582)], 'zero-shot': [(1, 2, 0.24082399653118497), (4, 6, 0.4013733275519749)], 'set': [(1, 1, 0.12041199826559248), (5, 2, 0.24082399653118497)], 'trec': [(1, 1, 0.07958800173440753), (4, 1, 0.04421555651911529), (5, 2, 0.15917600346881505), (6, 1, 0.03617636442473069)], '2019': [(1, 1, 0.16901960800285137)], '2020': [(1, 1, 0.16901960800285137)], 'deep': [(1, 1, 0.09542425094393249), (2, 1, 0.059640156839957804), (6, 1, 0.043374659519969314)], 'learn': [(1, 1, 0.07958800173440753), (2, 2, 0.0994850021680094), (5, 5, 0.3979400086720376), (6, 2, 0.07235272884946138)], 'track': [(1, 1, 0.16901960800285137)], 'show': [(1, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'achiev': [(1, 1, 0.16901960800285137)], 'effect': [(1, 2, 0.13696907232888253), (2, 1, 0.042802835102775785), (3, 2, 0.08560567020555157), (4, 5, 0.1902348226790035), (5, 1, 0.06848453616444126)], 'compar': [(1, 1, 0.07958800173440753), (2, 1, 0.0497425010840047), (3, 1, 0.0497425010840047), (4, 1, 0.04421555651911529)], 'gpt-3.5': [(1, 1, 0.16901960800285137)], 'much': [(1, 1, 0.16901960800285137)], 'smaller': [(1, 1, 0.16901960800285137)], '7b': [(1, 1, 0.16901960800285137)], 'paramet': [(1, 1, 0.16901960800285137)], 'although': [(1, 1, 0.16901960800285137)], 'remain': [(1, 1, 0.16901960800285137)], 'slightli': [(1, 1, 0.16901960800285137)], 'gpt-4': [(1, 1, 0.16901960800285137)], 'hope': [(1, 1, 0.16901960800285137)], 'provid': [(1, 1, 0.16901960800285137)], 'futur': [(1, 1, 0.16901960800285137)], 'modern': [(1, 1, 0.16901960800285137)], 'advent': [(2, 1, 0.1056372550017821)], 'transformer-bas': [(2, 3, 0.3169117650053463)], 'architectur': [(2, 2, 0.2112745100035642)], 'contextu': [(2, 2, 0.2112745100035642)], 'represent': [(2, 3, 0.3169117650053463)], 'text': [(2, 4, 0.4225490200071284)], 'data': [(2, 1, 0.0752574989159953), (6, 1, 0.05473272648436022)], 'leverag': [(2, 1, 0.0752574989159953), (6, 1, 0.05473272648436022)], 'queri': [(2, 8, 0.3979400086720376), (3, 8, 0.3979400086720376), (5, 4, 0.3183520069376301), (6, 2, 0.07235272884946138)], 'document': [(2, 7, 0.2996198457194305), (3, 3, 0.12840850530832737), (4, 2, 0.0760939290716014), (5, 4, 0.27393814465776506), (6, 2, 0.062258669240401146)], 'repres': [(2, 1, 0.0752574989159953), (3, 1, 0.0752574989159953)], 'low-dimension': [(2, 1, 0.1056372550017821)], 'dens': [(2, 3, 0.22577249674798588), (5, 2, 0.24082399653118497)], 'vector': [(2, 5, 0.5281862750089105)], 'space': [(2, 2, 0.1505149978319906), (6, 2, 0.10946545296872044)], 'embed': [(2, 1, 0.059640156839957804), (5, 4, 0.38169700377572996), (6, 2, 0.08674931903993863)], 'fix': [(2, 1, 0.1056372550017821)], 'size': [(2, 1, 0.0752574989159953), (4, 1, 0.06689555459199582)], 'deeper': [(2, 2, 0.2112745100035642)], 'understand': [(2, 2, 0.2112745100035642)], 'studi': [(2, 2, 0.1505149978319906), (4, 1, 0.06689555459199582)], 'design': [(2, 1, 0.0752574989159953), (3, 1, 0.0752574989159953)], 'pipelin': [(2, 1, 0.1056372550017821)], 'search': [(2, 1, 0.0752574989159953), (5, 2, 0.24082399653118497)], 'combin': [(2, 1, 0.1056372550017821)], 'bert': [(2, 2, 0.2112745100035642)], 'phrase': [(2, 2, 0.2112745100035642)], 'embedding-bas': [(2, 2, 0.1505149978319906), (5, 1, 0.12041199826559248)], 'expans': [(2, 2, 0.1505149978319906), (6, 4, 0.21893090593744088)], 'fine-tun': [(2, 1, 0.1056372550017821)], 'semant': [(2, 2, 0.11928031367991561), (5, 1, 0.09542425094393249), (6, 1, 0.043374659519969314)], 'match': [(2, 2, 0.1505149978319906), (6, 1, 0.05473272648436022)], 'separ': [(2, 2, 0.2112745100035642)], 'encod': [(2, 2, 0.1505149978319906), (5, 2, 0.24082399653118497)], 'base': [(2, 1, 0.059640156839957804), (3, 1, 0.059640156839957804), (6, 1, 0.043374659519969314)], 'sentenc': [(2, 1, 0.1056372550017821)], 'sbert': [(2, 1, 0.1056372550017821)], 'gener': [(2, 1, 0.0752574989159953), (6, 2, 0.10946545296872044)], 'also': [(2, 1, 0.0497425010840047), (3, 1, 0.0497425010840047), (4, 1, 0.04421555651911529), (6, 1, 0.03617636442473069)], 'maximum': [(2, 1, 0.1056372550017821)], 'token': [(2, 1, 0.0752574989159953), (4, 2, 0.13379110918399165)], 'length': [(2, 1, 0.1056372550017821)], 'limit': [(2, 1, 0.0752574989159953), (3, 1, 0.0752574989159953)], 'summar': [(2, 1, 0.1056372550017821)], 'lengthi': [(2, 1, 0.1056372550017821)], 'addit': [(2, 1, 0.059640156839957804), (3, 1, 0.059640156839957804), (6, 1, 0.043374659519969314)], 'improv': [(2, 1, 0.059640156839957804), (4, 1, 0.05301347274662915), (6, 1, 0.043374659519969314)], 'clariti': [(2, 1, 0.1056372550017821)], 'complet': [(2, 1, 0.1056372550017821)], 'short': [(2, 1, 0.1056372550017821)], 'reduc': [(2, 1, 0.0752574989159953), (4, 2, 0.13379110918399165)], 'gap': [(2, 1, 0.0752574989159953), (6, 1, 0.05473272648436022)], 'employ': [(2, 1, 0.1056372550017821)], 'index': [(2, 1, 0.0752574989159953), (5, 2, 0.24082399653118497)], 'use': [(2, 2, 0.08560567020555157), (3, 1, 0.042802835102775785), (4, 1, 0.0380469645358007), (5, 2, 0.13696907232888253), (6, 3, 0.09338800386060171)], 'elasticsearch': [(2, 1, 0.1056372550017821)], 'engin': [(2, 1, 0.1056372550017821)], 'query-specif': [(2, 1, 0.1056372550017821)], 'final': [(2, 2, 0.2112745100035642)], 'bert-bas': [(2, 1, 0.1056372550017821)], 'cross-encod': [(2, 1, 0.1056372550017821)], 're-rank': [(2, 1, 0.1056372550017821)], 'relev': [(2, 1, 0.0497425010840047), (3, 3, 0.14922750325201412), (5, 1, 0.07958800173440753), (6, 2, 0.07235272884946138)], 'record': [(2, 1, 0.1056372550017821)], 'full': [(2, 1, 0.1056372550017821)], 'self-attent': [(2, 1, 0.1056372550017821)], 'input': [(2, 1, 0.1056372550017821)], 'richer': [(2, 1, 0.1056372550017821)], 'interact': [(2, 1, 0.0752574989159953), (6, 2, 0.10946545296872044)], 'produc': [(2, 2, 0.1505149978319906), (3, 1, 0.0752574989159953)], 'assess': [(2, 1, 0.1056372550017821)], 'experi': [(2, 1, 0.1056372550017821)], 'conduct': [(2, 1, 0.1056372550017821)], 'two': [(2, 1, 0.0752574989159953), (5, 1, 0.12041199826559248)], 'well-known': [(2, 1, 0.1056372550017821)], 'dataset': [(2, 1, 0.042802835102775785), (3, 6, 0.25681701061665474), (4, 1, 0.0380469645358007), (5, 1, 0.06848453616444126), (6, 1, 0.031129334620200573)], 'trec-cds-2014': [(2, 1, 0.1056372550017821)], 'ohsum': [(2, 1, 0.1056372550017821)], 'analysi': [(2, 1, 0.1056372550017821)], 'carri': [(2, 1, 0.1056372550017821)], 'clearli': [(2, 1, 0.1056372550017821)], 'demonstr': [(2, 1, 0.0497425010840047), (4, 2, 0.08843111303823058), (5, 1, 0.07958800173440753), (6, 1, 0.03617636442473069)], 'propos': [(2, 1, 0.042802835102775785), (3, 1, 0.042802835102775785), (4, 2, 0.0760939290716014), (5, 1, 0.06848453616444126), (6, 3, 0.09338800386060171)], 'framework': [(2, 1, 0.059640156839957804), (3, 1, 0.059640156839957804), (4, 1, 0.05301347274662915)], 'competit': [(2, 1, 0.1056372550017821)], 'scientif': [(3, 4, 0.4225490200071284)], 'abil': [(3, 1, 0.1056372550017821)], 'complex': [(3, 7, 0.7394607850124747)], 'multifacet': [(3, 2, 0.2112745100035642)], 'critic': [(3, 1, 0.1056372550017821)], 'exist': [(3, 1, 0.059640156839957804), (4, 1, 0.05301347274662915), (6, 1, 0.043374659519969314)], 'evalu': [(3, 2, 0.11928031367991561), (4, 2, 0.1060269454932583), (6, 1, 0.043374659519969314)], 'task': [(3, 3, 0.22577249674798588), (4, 1, 0.06689555459199582)], 'primarili': [(3, 1, 0.1056372550017821)], 'due': [(3, 2, 0.2112745100035642)], 'high': [(3, 1, 0.0752574989159953), (4, 3, 0.20068666377598746)], 'cost': [(3, 2, 0.1505149978319906), (4, 1, 0.06689555459199582)], 'effort': [(3, 1, 0.1056372550017821)], 'requir': [(3, 2, 0.2112745100035642)], 'annot': [(3, 6, 0.6338235300106926)], 'resourc': [(3, 1, 0.1056372550017821)], 'novel': [(3, 1, 0.0752574989159953), (4, 1, 0.06689555459199582)], 'multi-level': [(3, 1, 0.1056372550017821)], 'aspect-bas': [(3, 1, 0.1056372550017821)], 'doris-ma': [(3, 4, 0.4225490200071284)], 'handl': [(3, 2, 0.2112745100035642)], 'natur': [(3, 1, 0.1056372550017821)], 'user': [(3, 1, 0.1056372550017821)], 'develop': [(3, 1, 0.1056372550017821)], 'benchmark': [(3, 1, 0.059640156839957804), (4, 1, 0.05301347274662915), (5, 2, 0.19084850188786498)], 'within': [(3, 1, 0.0752574989159953), (4, 1, 0.06689555459199582)], 'field': [(3, 1, 0.1056372550017821)], 'comput': [(3, 1, 0.0497425010840047), (4, 2, 0.08843111303823058), (5, 1, 0.07958800173440753), (6, 1, 0.03617636442473069)], 'scienc': [(3, 1, 0.1056372550017821)], 'consist': [(3, 1, 0.0752574989159953), (4, 1, 0.06689555459199582)], '100': [(3, 2, 0.2112745100035642)], 'human-author': [(3, 1, 0.1056372550017821)], 'case': [(3, 2, 0.2112745100035642)], 'assembl': [(3, 1, 0.1056372550017821)], 'collect': [(3, 1, 0.0752574989159953), (6, 1, 0.05473272648436022)], 'score': [(3, 1, 0.0752574989159953), (4, 1, 0.06689555459199582)], 'rank': [(3, 1, 0.0497425010840047), (4, 7, 0.309508895633807), (5, 1, 0.07958800173440753), (6, 2, 0.07235272884946138)], 'recogn': [(3, 1, 0.1056372550017821)], 'labor': [(3, 1, 0.1056372550017821)], 'expert': [(3, 1, 0.1056372550017821)], 'introduc': [(3, 1, 0.0752574989159953), (5, 1, 0.12041199826559248)], 'anno-gpt': [(3, 1, 0.1056372550017821)], 'scalabl': [(3, 1, 0.1056372550017821)], 'valid': [(3, 1, 0.1056372550017821)], 'expert-level': [(3, 1, 0.1056372550017821)], '500x': [(3, 1, 0.1056372550017821)], 'reduct': [(3, 1, 0.1056372550017821)], 'without': [(3, 2, 0.2112745100035642)], 'compromis': [(3, 1, 0.1056372550017821)], 'qualiti': [(3, 1, 0.1056372550017821)], 'furthermor': [(3, 1, 0.1056372550017821)], 'multi-ti': [(3, 1, 0.1056372550017821)], 'structur': [(3, 1, 0.0752574989159953), (5, 3, 0.3612359947967774)], 'extend': [(3, 1, 0.1056372550017821)], '4,000': [(3, 1, 0.1056372550017821)], 'sub-queri': [(3, 1, 0.1056372550017821)], 'test': [(3, 1, 0.059640156839957804), (4, 1, 0.05301347274662915), (6, 1, 0.043374659519969314)], '17': [(3, 1, 0.1056372550017821)], 'recent': [(3, 1, 0.0752574989159953), (6, 1, 0.05473272648436022)], 'method': [(3, 1, 0.059640156839957804), (4, 1, 0.05301347274662915), (5, 1, 0.09542425094393249)], 'observ': [(3, 1, 0.1056372550017821)], 'notabl': [(3, 1, 0.1056372550017821)], 'drop': [(3, 1, 0.1056372550017821)], 'tradit': [(3, 1, 0.0752574989159953), (6, 2, 0.10946545296872044)], 'highlight': [(3, 1, 0.1056372550017821)], 'need': [(3, 1, 0.1056372550017821)], 'better': [(3, 1, 0.1056372550017821)], 'impress': [(4, 1, 0.09389978222380631)], 'pointwis': [(4, 2, 0.18779956444761262)], 'pairwis': [(4, 2, 0.18779956444761262)], 'prompt': [(4, 3, 0.28169934667141894)], 'llm-base': [(4, 3, 0.28169934667141894)], 'begin': [(4, 1, 0.09389978222380631)], 'thoroughli': [(4, 1, 0.09389978222380631)], 'consid': [(4, 1, 0.09389978222380631)], 'factor': [(4, 1, 0.09389978222380631)], 'like': [(4, 1, 0.06689555459199582), (5, 1, 0.12041199826559248)], 'consumpt': [(4, 2, 0.18779956444761262)], 'latenc': [(4, 1, 0.09389978222380631)], 'among': [(4, 1, 0.09389978222380631)], 'other': [(4, 1, 0.09389978222380631)], 'first-of-its-kind': [(4, 1, 0.09389978222380631)], 'allow': [(4, 1, 0.06689555459199582), (6, 1, 0.05473272648436022)], 'us': [(4, 1, 0.09389978222380631)], 'identifi': [(4, 1, 0.09389978222380631)], 'trade-off': [(4, 1, 0.09389978222380631)], 'effici': [(4, 4, 0.2675822183679833), (5, 2, 0.24082399653118497)], 'inher': [(4, 1, 0.09389978222380631)], 'find': [(4, 1, 0.06689555459199582), (5, 1, 0.12041199826559248)], 'suffer': [(4, 1, 0.09389978222380631)], 'poor': [(4, 1, 0.09389978222380631)], 'convers': [(4, 1, 0.09389978222380631)], 'superior': [(4, 1, 0.09389978222380631)], 'incur': [(4, 1, 0.09389978222380631)], 'overhead': [(4, 1, 0.09389978222380631)], 'enhanc': [(4, 1, 0.09389978222380631)], 'setwis': [(4, 1, 0.09389978222380631)], 'number': [(4, 1, 0.09389978222380631)], 'infer': [(4, 1, 0.09389978222380631)], 'amount': [(4, 1, 0.09389978222380631)], 'procedur': [(4, 1, 0.09389978222380631)], 'significantli': [(4, 1, 0.09389978222380631)], 'dl': [(4, 1, 0.09389978222380631)], 'beir': [(4, 1, 0.09389978222380631)], 'empir': [(4, 1, 0.09389978222380631)], 'indic': [(4, 1, 0.09389978222380631)], 'consider': [(4, 1, 0.09389978222380631)], 'retain': [(4, 1, 0.09389978222380631)], 'industri': [(5, 2, 0.33803921600570275)], 'standard': [(5, 3, 0.3612359947967774), (6, 1, 0.05473272648436022)], 'problem': [(5, 1, 0.16901960800285137)], 'obtain': [(5, 1, 0.16901960800285137)], 'web': [(5, 1, 0.16901960800285137)], 'given': [(5, 2, 0.33803921600570275)], 'techniqu': [(5, 1, 0.16901960800285137)], 'two-stag': [(5, 1, 0.16901960800285137)], 'process': [(5, 1, 0.16901960800285137)], 'contrast': [(5, 1, 0.16901960800285137)], 'train': [(5, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'dual': [(5, 2, 0.33803921600570275)], 'emb': [(5, 1, 0.16901960800285137)], 'b': [(5, 1, 0.16901960800285137)], 'approxim': [(5, 1, 0.16901960800285137)], 'nearest': [(5, 1, 0.16901960800285137)], 'neighbor': [(5, 1, 0.16901960800285137)], 'ann': [(5, 5, 0.8450980400142568)], 'similar': [(5, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'stage': [(5, 1, 0.16901960800285137)], 'disjoint': [(5, 1, 0.16901960800285137)], 'might': [(5, 1, 0.16901960800285137)], 'ill-suit': [(5, 1, 0.16901960800285137)], 'vice-versa': [(5, 1, 0.16901960800285137)], 'lead': [(5, 1, 0.16901960800285137)], 'suboptim': [(5, 1, 0.16901960800285137)], 'end-to-end': [(5, 1, 0.16901960800285137)], 'hierarch': [(5, 1, 0.16901960800285137)], 'ehi': [(5, 5, 0.8450980400142568)], 'jointli': [(5, 1, 0.16901960800285137)], 'optim': [(5, 1, 0.16901960800285137)], 'invert': [(5, 1, 0.16901960800285137)], 'file': [(5, 1, 0.16901960800285137)], 'ivf': [(5, 1, 0.16901960800285137)], 'style': [(5, 1, 0.16901960800285137)], 'tree': [(5, 2, 0.33803921600570275)], 'ensur': [(5, 1, 0.16901960800285137)], 'stabl': [(5, 1, 0.16901960800285137)], 'discret': [(5, 1, 0.16901960800285137)], 'tree-bas': [(5, 1, 0.16901960800285137)], 'notion': [(5, 1, 0.16901960800285137)], 'path': [(5, 1, 0.16901960800285137)], 'captur': [(5, 1, 0.16901960800285137)], 'posit': [(5, 1, 0.16901960800285137)], 'query/docu': [(5, 1, 0.16901960800285137)], 'sever': [(5, 1, 0.16901960800285137)], 'includ': [(5, 1, 0.16901960800285137)], 'de-facto': [(5, 1, 0.16901960800285137)], 'ms': [(5, 2, 0.24082399653118497), (6, 1, 0.05473272648436022)], 'marco': [(5, 2, 0.24082399653118497), (6, 1, 0.05473272648436022)], 'dev': [(5, 2, 0.33803921600570275)], 'dl19': [(5, 2, 0.33803921600570275)], 'exampl': [(5, 1, 0.16901960800285137)], 'budget': [(5, 1, 0.16901960800285137)], 'outperform': [(5, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'state-of-the-art': [(5, 1, 0.12041199826559248), (6, 1, 0.05473272648436022)], 'sota': [(5, 1, 0.16901960800285137)], '0.6%': [(5, 1, 0.16901960800285137)], 'mrr@10': [(5, 1, 0.16901960800285137)], '4.2%': [(5, 1, 0.16901960800285137)], 'ndcg@10': [(5, 1, 0.16901960800285137)], 'qe': [(6, 4, 0.30730837818700246)], 'commonli': [(6, 1, 0.07682709454675062)], 'ir': [(6, 2, 0.15365418909350123)], 'adopt': [(6, 1, 0.07682709454675062)], 'neural': [(6, 3, 0.23048128364025183)], 'emerg': [(6, 1, 0.07682709454675062)], 'year': [(6, 1, 0.07682709454675062)], 'mani': [(6, 1, 0.07682709454675062)], 'focu': [(6, 1, 0.07682709454675062)], 'query-docu': [(6, 3, 0.23048128364025183)], 'term': [(6, 1, 0.07682709454675062)], 'howev': [(6, 1, 0.07682709454675062)], 'often': [(6, 1, 0.07682709454675062)], 'ignor': [(6, 1, 0.07682709454675062)], 'aim': [(6, 1, 0.07682709454675062)], 'condit': [(6, 1, 0.07682709454675062)], 'variat': [(6, 1, 0.07682709454675062)], 'autoencod': [(6, 1, 0.07682709454675062)], 'map': [(6, 1, 0.07682709454675062)], 'pair': [(6, 1, 0.07682709454675062)], 'latent': [(6, 2, 0.15365418909350123)], 'estim': [(6, 1, 0.07682709454675062)], 'feedback': [(6, 2, 0.15365418909350123)], 'pseudo-relev': [(6, 1, 0.07682709454675062)], 'time': [(6, 1, 0.07682709454675062)], 'three': [(6, 1, 0.07682709454675062)], 'ap': [(6, 1, 0.07682709454675062)], 'robust': [(6, 1, 0.07682709454675062)], '04': [(6, 1, 0.07682709454675062)], 'gov02': [(6, 1, 0.07682709454675062)], 'passag': [(6, 1, 0.07682709454675062)], 'higher': [(6, 1, 0.07682709454675062)], 'baselin': [(6, 1, 0.07682709454675062)]}\n",
      "358\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(os.path.abspath(\"Collection\"))\n",
    "dict = index(files, Inverse=True, Tokenize=True, PorterStemmer=True)\n",
    "write_dict_to_file(dict, \"InverseTokenPorter.txt\")\n",
    "        \n",
    "print(dict)\n",
    "print(len(dict))\n",
    "print(\"*************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(files, Tokenize, PorterStemmer):\n",
    "    docs = {}\n",
    "\n",
    "    for filename in files: \n",
    "        with open(os.path.join(\"Collection\", filename), \"r\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "            if Tokenize:\n",
    "                tokens = tokenization(text)\n",
    "            else:\n",
    "                tokens = text.split()\n",
    "\n",
    "            tokens_without_stopwords = stop_words(tokens)\n",
    "\n",
    "            if PorterStemmer:\n",
    "                normalized_words = normalization_porter(tokens_without_stopwords)\n",
    "            else:\n",
    "                normalized_words = normalization_lancaster(tokens_without_stopwords)\n",
    "            \n",
    "            file_id = int(re.search(r'\\d+', os.path.basename(filename)).group())\n",
    "            docs[file_id] = normalized_words\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query, Tokenize, PorterStemmer):\n",
    "    if Tokenize:\n",
    "        q = tokenization(query)\n",
    "    else :\n",
    "        q = query.split()\n",
    "    if PorterStemmer:\n",
    "        q = normalization_porter(q)\n",
    "    else:\n",
    "        q = normalization_lancaster(q)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_ids(files):\n",
    "    docs_id = []\n",
    "    for filename in files: \n",
    "        file_id = int(re.search(r'\\d+', os.path.basename(filename)).group())\n",
    "        docs_id.append(file_id)\n",
    "    return docs_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_product(query, file_path):\n",
    "    terms_by_doc = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            term, doc_id, freq, weight = line.split()\n",
    "            if term in query:\n",
    "                weight = float(weight) \n",
    "\n",
    "                if doc_id in terms_by_doc:\n",
    "                    terms_by_doc[doc_id] += weight\n",
    "                else:\n",
    "                    terms_by_doc[doc_id] = weight\n",
    "\n",
    "    terms_by_doc = sorted(terms_by_doc.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return terms_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_measure(query, file_path):\n",
    "    terms_by_doc = scalar_product(query, file_path)\n",
    "    weight_by_doc = {}\n",
    "    result_by_doc = {}\n",
    "    sum_vi = len(query)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            term, doc, freq, weight = line.split()\n",
    "            weight = float(weight) \n",
    "  \n",
    "            if doc in weight_by_doc:\n",
    "                weight_by_doc[doc] += weight**2\n",
    "            else:\n",
    "                weight_by_doc[doc] = weight**2\n",
    "\n",
    "    sum_vi = math.sqrt(sum_vi)\n",
    "    \n",
    "    for doc, sum_squared in weight_by_doc.items():\n",
    "        weight_by_doc[doc] = math.sqrt(sum_squared)\n",
    "\n",
    "    for doc, terms in terms_by_doc.items():\n",
    "        result_by_doc[doc] = terms / (sum_vi * weight_by_doc[doc])\n",
    "\n",
    "    result_by_doc= sorted(result_by_doc.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return result_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_measure(query, file_path):\n",
    "    terms_by_doc = scalar_product(query, file_path)\n",
    "    weight_by_doc = {}\n",
    "    result_by_doc = {}\n",
    "    sum_vi = len(query)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            term, doc, freq, weight = line.split()\n",
    "            weight = float(weight)  \n",
    "  \n",
    "            if doc in weight_by_doc:\n",
    "                weight_by_doc[doc] += weight**2\n",
    "            else:\n",
    "                weight_by_doc[doc] = weight**2\n",
    "\n",
    "    for doc, terms in terms_by_doc.items():\n",
    "        result_by_doc[doc] = terms / (sum_vi + weight_by_doc[doc] - terms)\n",
    "\n",
    "    result_by_doc= sorted(result_by_doc.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return result_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file(Tokenize, PorterStemmer):\n",
    "    if Tokenize:\n",
    "        if PorterStemmer:\n",
    "            return \"InverseTokenPorter.txt\"\n",
    "        else:\n",
    "            return \"InverseTokenLancaster.txt\"\n",
    "    else:\n",
    "        if PorterStemmer:\n",
    "            return \"InverseSplitPorter.txt\"\n",
    "        else:\n",
    "            return \"InverseSplitLancaster.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorial_model(query, Tokenize, PorterStemmer, SP, cosine, jaccard):\n",
    "        query = preprocess_query(query, Tokenize, PorterStemmer)\n",
    "        file_path = file(Tokenize, PorterStemmer)\n",
    "        if SP:\n",
    "            result = scalar_product(query, file_path)\n",
    "        else: \n",
    "            if cosine:\n",
    "                result = cosine_measure(query, file_path)\n",
    "            else:\n",
    "                if jaccard:\n",
    "                    result = jaccard_measure(query, file_path)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_docs_terms(file_path, query):\n",
    "    documents_containing_terms = {}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            current_term, _, _, _ = line.strip().split()\n",
    "\n",
    "            if current_term in query:\n",
    "                if current_term not in documents_containing_terms:\n",
    "                    documents_containing_terms[current_term] = 1\n",
    "                else:\n",
    "                    documents_containing_terms[current_term] += 1\n",
    "            elif len(documents_containing_terms) == len(query):\n",
    "                # If we have encountered all terms and the next one is different, stop the loop\n",
    "                break\n",
    "    return documents_containing_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query, file_path, K, B):\n",
    "    dl = {}\n",
    "    result = {}\n",
    "    vocab_len = 0\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            _, doc_id, freq, _ = line.strip().split()\n",
    "            dl[doc_id] = dl.get(doc_id, 0) + int(freq)\n",
    "            vocab_len += int(freq)\n",
    "\n",
    "    N = len(dl)\n",
    "    avdl = vocab_len / N\n",
    "    ni = n_docs_terms(file_path, query)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            term, doc, freq, _ = line.split()\n",
    "            freq = int(freq)\n",
    "            if term in query:\n",
    "                if doc in result:\n",
    "                    result[doc] += ((freq / (K * ((1 - B) + B * (dl[doc] / avdl)) + freq)) * np.log10(((N - ni[term] + 0.5) / (ni[term] + 0.5))))\n",
    "                else:\n",
    "                    result[doc] = ((freq / (K * ((1 - B) + B * (dl[doc] / avdl)) + freq)) * np.log10(((N - ni[term] + 0.5) / (ni[term] + 0.5))))\n",
    "                    \n",
    "    result = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_model(query, Tokenize, PorterStemmer, K, B):\n",
    "    query = preprocess_query(query, Tokenize, PorterStemmer)\n",
    "    file_path = file(Tokenize, PorterStemmer)\n",
    "    result = BM25(query, file_path, K, B)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_query(query):\n",
    "    \n",
    "    if isinstance(query, list):\n",
    "        query = ' '.join(query)\n",
    "\n",
    "    # reg expresssion \n",
    "    reg_exp = r'\\b(?:((?:[A-Za-z]\\.)+|[A-Za-z]+[\\-@]\\d+(?:\\.\\d+)?|\\d+[A-Za-z]+|\\d+(?:[\\.\\,]\\d+)?%?|\\w+(?:[\\-/]\\w+)*)\\b|and|or|not)\\b'\n",
    "\n",
    "    matches = re.findall(reg_exp, query)\n",
    "\n",
    "    if not is_valid_boolean_query(matches):\n",
    "        print(\"La requête n'est pas valide.\")\n",
    "        return None\n",
    "    return matches\n",
    "\n",
    "def is_valid_boolean_query(matches):\n",
    "    if not matches:\n",
    "        return False\n",
    "\n",
    "    operators = {'and', 'or', 'not'}\n",
    "    for match in matches:\n",
    "        if match not in operators and not re.match(r'\\b\\w+\\b', match):\n",
    "            return False\n",
    "    \n",
    "    # operator order\n",
    "    if matches[0] in operators-{'not'} or matches[-1] in operators:\n",
    "        return False\n",
    "    \n",
    "    # NOT & term term \n",
    "    for i in range(len(matches) - 1):\n",
    "        if matches[i] == 'not' and ((not matches[i + 1]) or (matches[i+1] in operators)):\n",
    "            return False\n",
    "        if  matches[i] not in operators and matches[i+1] not in operators:\n",
    "            print(matches[i])\n",
    "            return False\n",
    "        \n",
    "    #  AND OR / OR AND\n",
    "    for i in range(len(matches) - 2):\n",
    "        if matches[i] in operators-{'not'} and matches[i + 1] in operators-{'not'}:\n",
    "            return False\n",
    "        \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_query_evaluation(query, dict, docs_id):\n",
    "\n",
    "    terms_and_operators = boolean_query(query)\n",
    "    if terms_and_operators == None:\n",
    "        return None\n",
    "    else:\n",
    "        \n",
    "        result_set = set(docs_id)\n",
    "\n",
    "        operator_stack = []\n",
    "\n",
    "        for token in terms_and_operators:\n",
    "            if token == 'not':\n",
    "                operator_stack.append('not')\n",
    "            elif token == 'and':\n",
    "                operator_stack.append('and')\n",
    "            elif token == 'or':\n",
    "                operator_stack.append('or')\n",
    "            else:\n",
    "                term_results = set(tup[0] for tup in dict[token]) if token in dict else set()\n",
    "                if 'not' in operator_stack:\n",
    "                    term_results = set(docs_id) - term_results\n",
    "                    operator_stack.remove('not')\n",
    "                if 'and' in operator_stack:\n",
    "                    result_set = result_set.intersection(term_results)\n",
    "                    operator_stack.remove('and')\n",
    "                elif 'or' in operator_stack:\n",
    "                    result_set = result_set.union(term_results)\n",
    "                    operator_stack.remove('or')\n",
    "                else:\n",
    "                    result_set = term_results\n",
    "\n",
    "        return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_model(query, files, Tokenize, PorterStemmer):\n",
    "    result_dict = {}\n",
    "    query = preprocess_query(query, Tokenize, PorterStemmer)\n",
    "    docs_id = get_docs_ids(files)\n",
    "    dict = index(files, True, Tokenize, PorterStemmer)\n",
    "    results = boolean_query_evaluation(query, dict, docs_id)\n",
    "    if results != None:\n",
    "        for doc in docs_id:\n",
    "            if doc in results:\n",
    "                result_dict[doc] = 'YES'\n",
    "            else:\n",
    "                result_dict[doc] = 'NO'\n",
    "    else:\n",
    "        result_dict = None\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avdl= 127.33333333333333\n",
      "dict des documents de chaque terme: {'document': 5, 'rank': 4}\n",
      "dl[doc]= 145\n",
      "doc= 3\n",
      "dl[doc]= 123\n",
      "doc= 4\n",
      "dl[doc]= 137\n",
      "doc= 5\n",
      "dl[doc]= 120\n",
      "doc= 6\n",
      "[('2', -0.4530776383132547), ('3', -0.45967871691057005), ('6', -0.47714350676623185), ('5', -0.5028401178205029), ('4', -0.5371824829383636)]\n"
     ]
    }
   ],
   "source": [
    "query = \"Documents ranking\"\n",
    "res = probabilistic_model(query, Tokenize=True, PorterStemmer=True, K=1.50, B=0.75)\n",
    "#res2 = vectorial_model(query, Tokenize=True, PorterStemmer=True, SP=True, cosine=False, jaccard=False)\n",
    "#res3 = boolean_model(query, files, Tokenize=True, PorterStemmer=True)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(relevant_docs, retrieved_docs, cutoff=None):\n",
    "    total_retrieved = len(retrieved_docs[:cutoff])\n",
    "    if total_retrieved == 0:\n",
    "        return 0\n",
    "    relevant_retrieved = len(set(relevant_docs) & set(retrieved_docs[:cutoff]))\n",
    "    return relevant_retrieved / total_retrieved\n",
    "\n",
    "def recall(relevant_docs, retrieved_docs, cutoff=None):\n",
    "    total_relevant = len(relevant_docs)\n",
    "    if total_relevant == 0:\n",
    "        return 0\n",
    "    relevant_retrieved = len(set(relevant_docs) & set(retrieved_docs[:cutoff]))\n",
    "    return relevant_retrieved / total_relevant\n",
    "\n",
    "def f_score(precision_value, recall_value):\n",
    "    if precision_value + recall_value > 0:\n",
    "        return 2 * (precision_value * recall_value) / (precision_value + recall_value)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Have recent language models delivered competitive results in information retrieval?', 'What recent studies explore query expansion through embeddings?']\n",
      "[(1, 1), (1, 3), (1, 4), (2, 2), (2, 6)]\n"
     ]
    }
   ],
   "source": [
    "with open('Queries.txt', 'r') as queries_file:\n",
    "    queries = [line.strip() for line in queries_file]\n",
    "\n",
    "with open('Judgements.txt', 'r') as judgments_file:\n",
    "    judgments = [tuple(map(int, line.strip().split())) for line in judgments_file]\n",
    "\n",
    "print(queries)\n",
    "print(judgments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "vectorial_model() got multiple values for argument 'Tokenize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, query \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(queries, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mvectorial_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTokenize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPorterStemmer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaccard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     relevant_docs \u001b[38;5;241m=\u001b[39m [doc_id \u001b[38;5;28;01mfor\u001b[39;00m (q_id, doc_id) \u001b[38;5;129;01min\u001b[39;00m judgments \u001b[38;5;28;01mif\u001b[39;00m q_id \u001b[38;5;241m==\u001b[39m i]\n\u001b[0;32m      4\u001b[0m     selected_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mTypeError\u001b[0m: vectorial_model() got multiple values for argument 'Tokenize'"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries, start=1):\n",
    "    dict = vectorial_model(query, files, Tokenize=True, PorterStemmer=True, SP=True, cosine=False, jaccard=False)\n",
    "    relevant_docs = [doc_id for (q_id, doc_id) in judgments if q_id == i]\n",
    "    selected_docs = list(dict.keys())\n",
    "    selected_relevant_docs = [doc for doc in relevant_docs if doc in selected_docs]\n",
    "    # Metrics evaluation\n",
    "    precision_value = precision(selected_relevant_docs, selected_docs)\n",
    "    precision_5 = precision(selected_relevant_docs, selected_docs, 5)\n",
    "    precision_10 = precision(selected_relevant_docs, selected_docs, 10)\n",
    "    recall_value = recall(selected_relevant_docs, selected_docs)\n",
    "    f_score_value = f_score(precision_value, recall_value) \n",
    "    \n",
    "    print(f\"Query {i} Metrics:\")\n",
    "    print(f\"P@5: {precision_5}\")\n",
    "    print(f\"P@10: {precision_10}\")\n",
    "    print(f\"Recall: {recall_value}\")\n",
    "    print(f\"F-Score: {f_score_value}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
