research 1 2 0.24082
research 6 1 0.06690
success 1 1 0.16902
appli 1 1 0.16902
larg 1 1 0.07959
larg 2 1 0.06632
larg 3 1 0.07959
larg 4 1 0.05685
languag 1 1 0.09542
languag 3 1 0.09542
languag 4 1 0.06816
model 1 2 0.12041
model 2 6 0.30103
model 3 1 0.06021
model 4 2 0.08601
model 5 1 0.06021
model 6 9 0.30103
(llms) 1 1 0.09542
(llms) 3 1 0.09542
(llms) 4 1 0.06816
chatgpt 1 1 0.16902
rerank 1 5 0.84510
inform 1 1 0.12041
inform 6 1 0.06690
retriev 1 1 0.06848
retriev 2 3 0.17121
retriev 3 3 0.20545
retriev 5 2 0.13697
retriev 6 1 0.03805
context, 1 1 0.16902
date, 1 1 0.16902
work 1 2 0.33804
mostli 1 1 0.16902
built 1 1 0.16902
proprietari 1 1 0.16902
hidden 1 1 0.16902
behind 1 2 0.33804
opaqu 1 1 0.16902
api 1 1 0.16902
endpoints. 1 1 0.16902
approach 1 1 0.09542
approach 3 1 0.09542
approach 4 7 0.47712
yield 1 1 0.12041
yield 2 1 0.10034
experiment 1 2 0.24082
experiment 4 1 0.08601
result 1 2 0.13697
result 2 1 0.05707
result 3 1 0.06848
result 4 1 0.04892
result 6 1 0.03805
reproduc 1 1 0.16902
non-deterministic, 1 1 0.16902
threaten 1 1 0.16902
verac 1 1 0.16902
outcom 1 1 0.16902
build 1 1 0.16902
shaki 1 1 0.16902
foundations. 1 1 0.16902
address 1 1 0.07959
address 2 1 0.06632
address 3 1 0.07959
address 6 1 0.04422
signific 1 1 0.12041
signific 3 1 0.12041
shortcoming, 1 1 0.16902
present 1 1 0.16902
rankvicuna, 1 1 0.16902
first 1 1 0.12041
first 6 1 0.06690
fulli 1 1 0.16902
open-sourc 1 1 0.16902
llm 1 1 0.09542
llm 3 1 0.09542
llm 4 1 0.06816
capabl 1 1 0.12041
capabl 2 1 0.10034
perform 1 1 0.07959
perform 2 1 0.06632
perform 3 2 0.15918
perform 6 1 0.04422
high-qual 1 1 0.16902
listwis 1 1 0.12041
listwis 4 1 0.08601
zero-shot 1 2 0.24082
zero-shot 4 6 0.51605
setting. 1 1 0.16902
trec 1 1 0.07959
trec 4 1 0.05685
trec 5 2 0.15918
trec 6 1 0.04422
2019 1 1 0.16902
2020 1 1 0.16902
deep 1 1 0.09542
deep 2 1 0.07952
deep 6 1 0.05301
learn 1 1 0.07959
learn 2 2 0.13265
learn 5 5 0.39794
learn 6 2 0.08843
track 1 1 0.16902
show 1 1 0.12041
show 6 1 0.06690
achiev 1 1 0.16902
effect 1 2 0.13697
effect 2 1 0.05707
effect 3 2 0.13697
effect 4 3 0.14675
effect 5 1 0.06848
compar 1 1 0.07959
compar 2 1 0.06632
compar 3 1 0.07959
compar 4 1 0.05685
gpt-3.5 1 1 0.16902
much 1 1 0.16902
smaller 1 1 0.16902
7b 1 1 0.16902
paramet 1 1 0.16902
model, 1 1 0.16902
although 1 1 0.16902
remain 1 1 0.16902
slightli 1 1 0.16902
gpt-4. 1 1 0.16902
hope 1 1 0.16902
provid 1 1 0.16902
foundat 1 1 0.16902
futur 1 1 0.16902
modern 1 1 0.16902
llms. 1 1 0.16902
advent 2 1 0.14085
transformer-bas 2 3 0.42255
architectures, 2 1 0.14085
contextu 2 2 0.28170
represent 2 2 0.28170
text 2 4 0.56340
data 2 1 0.10034
data 6 1 0.06690
leverag 2 1 0.10034
leverag 6 1 0.06690
queri 2 5 0.33162
queri 3 5 0.39794
queri 5 2 0.15918
queri 6 2 0.08843
document 2 5 0.28535
document 3 3 0.20545
document 4 2 0.09784
document 5 4 0.27394
document 6 2 0.07609
repres 2 1 0.10034
repres 3 1 0.12041
low-dimension 2 1 0.14085
dens 2 3 0.30103
dens 5 2 0.24082
vector 2 5 0.70425
space. 2 1 0.10034
space. 6 1 0.06690
embed 2 1 0.07952
embed 5 4 0.38170
embed 6 2 0.10603
fix 2 1 0.14085
sizes, 2 1 0.14085
deeper 2 2 0.28170
understanding. 2 1 0.14085
study, 2 1 0.14085
design 2 1 0.10034
design 3 1 0.12041
pipelin 2 1 0.14085
search 2 1 0.10034
search 5 2 0.24082
space 2 1 0.10034
space 6 1 0.06690
combin 2 1 0.14085
understand 2 1 0.14085
bert 2 2 0.28170
phrase 2 2 0.28170
embedding-bas 2 2 0.20069
embedding-bas 5 1 0.12041
expans 2 2 0.20069
expans 6 4 0.26758
model. 2 1 0.14085
representations, 2 1 0.14085
fine-tun 2 1 0.14085
semant 2 2 0.15904
semant 5 1 0.09542
semant 6 1 0.05301
match 2 2 0.20069
match 6 1 0.06690
separ 2 2 0.28170
encod 2 2 0.20069
encod 5 2 0.24082
query. 2 2 0.20069
query. 5 2 0.24082
base 2 1 0.07952
base 3 1 0.09542
base 6 1 0.05301
sentenc 2 1 0.14085
(sbert) 2 1 0.14085
architecture, 2 1 0.14085
gener 2 1 0.10034
gener 6 2 0.13379
queries. 2 1 0.10034
queries. 3 1 0.12041
studi 2 1 0.10034
studi 4 1 0.08601
also 2 1 0.06632
also 3 1 0.07959
also 4 1 0.05685
also 6 1 0.04422
maximum 2 1 0.14085
token 2 1 0.10034
token 4 2 0.17202
length 2 1 0.14085
limit 2 1 0.14085
summar 2 1 0.14085
lengthi 2 1 0.14085
documents. 2 2 0.28170
addition, 2 1 0.14085
improv 2 1 0.07952
improv 4 1 0.06816
improv 6 1 0.05301
clariti 2 1 0.14085
complet 2 1 0.14085
short 2 1 0.14085
reduc 2 1 0.10034
reduc 4 2 0.17202
gap, 2 1 0.14085
employed. 2 1 0.14085
index 2 1 0.10034
index 5 2 0.24082
use 2 2 0.11414
use 3 1 0.06848
use 4 1 0.04892
use 5 2 0.13697
use 6 3 0.11414
elasticsearch 2 1 0.14085
engine, 2 1 0.14085
query-specif 2 1 0.14085
finally, 2 1 0.14085
bert-bas 2 1 0.14085
cross-encod 2 1 0.14085
re-rank 2 1 0.14085
relev 2 1 0.06632
relev 3 3 0.23876
relev 5 1 0.07959
relev 6 1 0.04422
record 2 1 0.14085
full 2 1 0.14085
self-attent 2 1 0.14085
inputs, 2 1 0.14085
richer 2 1 0.14085
interact 2 1 0.14085
produc 2 2 0.20069
produc 3 1 0.12041
final 2 1 0.14085
results. 2 2 0.28170
assess 2 1 0.14085
performance, 2 1 0.14085
experi 2 1 0.14085
conduct 2 1 0.14085
two 2 1 0.10034
two 5 1 0.12041
well-known 2 1 0.14085
datasets, 2 1 0.14085
trec-cds-2014 2 1 0.14085
ohsumed. 2 1 0.14085
analysi 2 1 0.14085
carri 2 1 0.14085
out, 2 1 0.14085
clearli 2 1 0.14085
demonstr 2 1 0.06632
demonstr 4 2 0.11370
demonstr 5 1 0.07959
demonstr 6 1 0.04422
propos 2 1 0.05707
propos 3 1 0.06848
propos 4 2 0.09784
propos 5 1 0.06848
propos 6 3 0.11414
framework 2 1 0.10034
framework 3 1 0.12041
competit 2 1 0.14085
scientif 3 4 0.67608
research, 3 1 0.12041
research, 6 1 0.06690
abil 3 1 0.16902
complex, 3 2 0.33804
multifacet 3 2 0.33804
critical. 3 1 0.16902
exist 3 1 0.09542
exist 4 1 0.06816
exist 6 1 0.05301
evalu 3 2 0.19085
evalu 4 2 0.13632
evalu 6 1 0.05301
dataset 3 5 0.47712
dataset 4 1 0.06816
dataset 6 1 0.05301
task 3 1 0.16902
limited, 3 1 0.16902
primarili 3 1 0.16902
due 3 2 0.33804
high 3 1 0.12041
high 4 3 0.25803
cost 3 1 0.12041
cost 4 1 0.08601
effort 3 1 0.16902
requir 3 2 0.33804
annot 3 4 0.67608
resourc 3 1 0.16902
complex 3 5 0.84510
this, 3 1 0.16902
novel 3 1 0.12041
novel 4 1 0.08601
task, 3 1 0.16902
multi-level 3 1 0.16902
aspect-bas 3 1 0.16902
(doris-mae), 3 1 0.16902
handl 3 2 0.33804
natur 3 1 0.16902
user 3 1 0.16902
research. 3 2 0.33804
develop 3 1 0.16902
benchmark 3 1 0.16902
within 3 1 0.12041
within 4 1 0.08601
field 3 1 0.16902
comput 3 1 0.07959
comput 4 2 0.11370
comput 5 1 0.07959
comput 6 1 0.04422
science, 3 1 0.16902
consist 3 1 0.12041
consist 4 1 0.08601
100 3 2 0.33804
human-author 3 1 0.16902
cases. 3 1 0.16902
query, 3 1 0.16902
assembl 3 1 0.16902
collect 3 1 0.12041
collect 6 1 0.06690
score 3 1 0.12041
score 4 1 0.08601
rank 3 1 0.09542
rank 4 4 0.27264
rank 5 1 0.09542
them. 3 1 0.16902
recogn 3 1 0.16902
labor 3 1 0.16902
expert 3 1 0.16902
annotation, 3 1 0.16902
introduc 3 1 0.12041
introduc 5 1 0.12041
anno-gpt, 3 1 0.16902
scalabl 3 1 0.16902
valid 3 1 0.16902
expert-level 3 1 0.16902
tasks. 3 1 0.12041
tasks. 4 1 0.08601
doris-ma 3 2 0.33804
500x 3 1 0.16902
reduct 3 1 0.16902
cost, 3 1 0.16902
without 3 2 0.33804
compromis 3 1 0.16902
quality. 3 1 0.16902
furthermore, 3 1 0.16902
multi-ti 3 1 0.16902
structur 3 1 0.12041
structur 5 2 0.24082
queries, 3 1 0.16902
extend 3 1 0.16902
4,000 3 1 0.16902
sub-queri 3 1 0.16902
test 3 1 0.09542
test 4 1 0.06816
test 6 1 0.05301
case 3 1 0.16902
addit 3 1 0.12041
addit 6 1 0.06690
annotation. 3 1 0.16902
17 3 1 0.16902
recent 3 1 0.12041
recent 6 1 0.06690
method 3 1 0.09542
method 4 1 0.06816
method 5 1 0.09542
doris-mae, 3 1 0.16902
observ 3 1 0.16902
notabl 3 1 0.16902
drop 3 1 0.16902
tradit 3 1 0.12041
tradit 6 2 0.13379
datasets. 3 1 0.12041
datasets. 5 1 0.12041
highlight 3 1 0.16902
need 3 1 0.16902
better 3 1 0.16902
impress 4 1 0.12073
pointwise, 4 1 0.12073
pairwise, 4 1 0.12073
prompt 4 3 0.36218
llm-base 4 3 0.36218
ranking. 4 2 0.17202
ranking. 6 1 0.06690
begin 4 1 0.12073
thoroughli 4 1 0.12073
framework, 4 1 0.12073
consid 4 1 0.12073
factor 4 1 0.12073
like 4 1 0.08601
like 5 1 0.12041
size, 4 1 0.12073
consumption, 4 1 0.12073
latency, 4 1 0.12073
among 4 1 0.12073
others. 4 1 0.12073
first-of-its-kind 4 1 0.12073
allow 4 1 0.08601
allow 6 1 0.06690
us 4 1 0.12073
identifi 4 1 0.12073
trade-off 4 1 0.12073
effici 4 3 0.25803
effici 5 2 0.24082
inher 4 1 0.12073
approach. 4 2 0.24146
find 4 1 0.08601
find 5 1 0.12041
pointwis 4 1 0.12073
efficiency, 4 1 0.12073
suffer 4 1 0.12073
poor 4 1 0.12073
effectiveness. 4 2 0.24146
conversely, 4 1 0.12073
pairwis 4 1 0.12073
superior 4 1 0.12073
incur 4 1 0.12073
overhead. 4 1 0.12073
enhanc 4 1 0.12073
ranking, 4 1 0.12073
setwis 4 1 0.12073
number 4 1 0.12073
infer 4 1 0.12073
amount 4 1 0.12073
consumpt 4 1 0.12073
procedure, 4 1 0.12073
significantli 4 1 0.12073
dl 4 1 0.12073
beir 4 1 0.12073
benchmark. 4 1 0.12073
empir 4 1 0.12073
indic 4 1 0.12073
consider 4 1 0.12073
retain 4 1 0.12073
industri 5 2 0.33804
standard 5 3 0.36124
standard 6 1 0.06690
problems, 5 1 0.16902
obtain 5 1 0.16902
web 5 1 0.16902
given 5 2 0.33804
techniqu 5 1 0.16902
two-stag 5 1 0.16902
process: 5 1 0.16902
(a) 5 1 0.16902
contrast 5 1 0.16902
train 5 1 0.12041
train 6 1 0.06690
dual 5 2 0.33804
emb 5 1 0.16902
(b) 5 1 0.16902
approxim 5 1 0.16902
nearest 5 1 0.16902
neighbor 5 1 0.16902
(anns) 5 1 0.16902
similar 5 1 0.12041
similar 6 1 0.06690
stage 5 1 0.16902
disjoint; 5 1 0.16902
might 5 1 0.16902
ill-suit 5 1 0.16902
ann 5 3 0.50706
vice-versa, 5 1 0.16902
lead 5 1 0.16902
suboptim 5 1 0.16902
performance. 5 2 0.33804
work, 5 1 0.16902
end-to-end 5 1 0.16902
hierarch 5 1 0.16902
-- 5 2 0.33804
ehi 5 5 0.84510
jointli 5 1 0.16902
optim 5 1 0.16902
invert 5 1 0.16902
file 5 1 0.16902
(ivf) 5 1 0.16902
style 5 1 0.16902
tree 5 1 0.16902
anns. 5 1 0.16902
ensur 5 1 0.16902
stabl 5 1 0.16902
discret 5 1 0.16902
tree-bas 5 1 0.16902
structure, 5 1 0.16902
notion 5 1 0.16902
path 5 1 0.16902
captur 5 1 0.16902
posit 5 1 0.16902
query/docu 5 1 0.16902
tree. 5 1 0.16902
sever 5 1 0.16902
benchmarks, 5 1 0.16902
includ 5 1 0.16902
de-facto 5 1 0.16902
ms 5 2 0.24082
ms 6 1 0.06690
marco 5 2 0.24082
marco 6 1 0.06690
(dev 5 1 0.16902
set 5 2 0.33804
dl19) 5 1 0.16902
example, 5 1 0.16902
budget, 5 1 0.16902
outperform 5 1 0.12041
outperform 6 1 0.06690
state-of-the-art 5 1 0.12041
state-of-the-art 6 1 0.06690
(sota) 5 1 0.16902
0.6% 5 1 0.16902
(mrr@10) 5 1 0.16902
dev 5 1 0.16902
4.2% 5 1 0.16902
(ndcg@10) 5 1 0.16902
dl19 5 1 0.16902
benchmarks. 5 1 0.16902
(qe) 6 1 0.09390
commonli 6 1 0.09390
(ir) 6 1 0.09390
models. 6 2 0.18780
adopt 6 1 0.09390
ir 6 1 0.09390
neural 6 3 0.28170
qe 6 3 0.28170
emerg 6 1 0.09390
years. 6 1 0.09390
mani 6 1 0.09390
focu 6 1 0.09390
query-docu 6 3 0.28170
relevance. 6 1 0.09390
terms. 6 1 0.09390
however, 6 1 0.09390
often 6 1 0.09390
ignor 6 1 0.09390
interactions. 6 1 0.09390
aim 6 1 0.09390
gap 6 1 0.09390
condit 6 1 0.09390
variat 6 1 0.09390
autoencoder. 6 1 0.09390
map 6 1 0.09390
pair 6 1 0.09390
latent 6 2 0.18780
interaction, 6 1 0.09390
estim 6 1 0.09390
feedback 6 2 0.18780
pseudo-relev 6 1 0.09390
time. 6 1 0.09390
three 6 1 0.09390
ranking: 6 1 0.09390
ap 6 1 0.09390
robust 6 1 0.09390
04 6 1 0.09390
gov02, 6 1 0.09390
passag 6 1 0.09390
higher 6 1 0.09390
baselines. 6 1 0.09390
